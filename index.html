<!-- <!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Camera Example</title>
  </head>
  <body>
    <h1>Camera Example</h1>
    <video id="videoElement" width="640" height="480" autoplay></video>
    <button onclick="startCamera()">Start Camera</button>
    <button onclick="stopCamera()">Stop Camera</button>

    <script>
      async function startCamera() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            video: true,
          });
          const videoElement = document.getElementById("videoElement");
          videoElement.srcObject = stream;
        } catch (error) {
          console.error("Error accessing camera:", error);
        }
      }

      function stopCamera() {
        const videoElement = document.getElementById("videoElement");
        const stream = videoElement.srcObject;
        const tracks = stream.getTracks();
        tracks.forEach((track) => track.stop());
        videoElement.srcObject = null;
      }
    </script>
  </body>
</html> -->
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>물 인증</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  </head>
  <body>
    <h1>물 인증</h1>
    <input type="file" id="upload-image" accept="image/*" capture="camera" />
    <div id="result"></div>
    <script>
      let model;

      async function loadModel() {
        const modelUrl = "web_model/model.json";
        model = await tf.loadGraphModel(modelUrl);
        document.getElementById("result").innerText =
          "Model loaded successfully!";
      }

      loadModel();

      document
        .getElementById("upload-image")
        .addEventListener("change", async (event) => {
          const file = event.target.files[0];
          if (!file) return;

          const img = document.createElement("img");
          img.src = URL.createObjectURL(file);
          img.onload = async () => {
            // 이미지를 640x640로 조정
            const tensor = tf.browser
              .fromPixels(img)
              .resizeNearestNeighbor([640, 640])
              .toFloat();

            // 이미지의 채널 순서를 변경하여 RGB로 변환
            const rgbTensor = tensor.reverse(-1);

            // 모델의 입력 형태에 맞게 전처리
            const preprocessedTensor = rgbTensor
              .transpose([2, 1, 0])
              .expandDims(0);

            console.log(preprocessedTensor);

            // 모델 실행
            const predictions = await model.execute(preprocessedTensor);

            console.log(predictions);

            // // 예측 결과에서 물 감지 여부 확인
            const isWater = predictions.dataSync()[0][0] > 0.5;

            // // 결과 표시
            // document.getElementById("result").innerText = isWater
            //   ? "물이 감지되었습니다!"
            //   : "물이 아닙니다!";
          };
        });
    </script>
  </body>
</html>
